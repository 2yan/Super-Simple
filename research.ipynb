{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rfrancis\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import doctor\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import main\n",
    "import seaborn as sea\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "import ryan_tools as rt\n",
    "import keras as kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_candles(candles, signal, fig, ax):\n",
    "    def add_rectangle(i, open_, close,low, high, ax, sig):\n",
    "        x = i - .5\n",
    "        y = min(open_, close)\n",
    "        height = abs(open_ - close)\n",
    "        if sig == 'buy':\n",
    "            color = 'green'\n",
    "            hatch = 'x'\n",
    "        if sig == 'sell':\n",
    "            color = 'red'\n",
    "            hatch = ''\n",
    "            \n",
    "        if sig == 'wait':\n",
    "            color = 'orange'\n",
    "            hatch = ''\n",
    "        ax.add_patch(patches.Rectangle((x, y), .9, height,\n",
    "                                       fill = open_ <= close, facecolor = color,\n",
    "                                       edgecolor = color, hatch = hatch ))\n",
    "        top = max(open_,close)\n",
    "        bottom = min(open_,close)\n",
    "\n",
    "        if low < bottom:\n",
    "            ax.add_line(mpl.lines.Line2D([i,i], [low, bottom], color = color) )\n",
    "\n",
    "            \n",
    "        if high > top:\n",
    "            ax.add_line(mpl.lines.Line2D([i,i], [high, top], color = color) )\n",
    "\n",
    "        \n",
    "    for i, index in enumerate(candles.index):\n",
    "        sig = signal.loc[index]\n",
    "        row = candles.loc[index]\n",
    "        add_rectangle(i, row['open'], row['close'],row['low'], row['high'],  ax, sig)\n",
    "    ax.set_xlim(0, len(candles))\n",
    "    ax.set_ylim(candles['close'].min() *.998, candles['close'].max() * 1.002)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chartio(gran = 60, cans = False, count = False):\n",
    "    if type(cans) == type(False):\n",
    "        cans = aba.get_candles(granularity= gran)\n",
    "    if count == False:\n",
    "        count = len(cans)\n",
    "    mask = cans['open']< cans['close']\n",
    "    signal = pd.Series(index = cans.index )\n",
    "    signal.loc[mask] = 'buy'\n",
    "    signal.loc[~mask] = 'sell'\n",
    "\n",
    "    \n",
    "    \n",
    "    fig, (ax, sig_ax) = plt.subplots(nrows = 2, sharex= False)\n",
    "    fig.set_size_inches(7, 9)\n",
    "    plot_candles(cans[-count:], signal[-count:], fig, ax)\n",
    "    ax.set_xticklabels(cans.index)\n",
    "    ax2 = ax.twinx()\n",
    "    cans.iloc[-count:]['volume'].plot(kind = 'bar', ax = ax2, alpha = 0.3)\n",
    "    \n",
    "\n",
    "    rsi = aba.get_rsi(cans['close'])\n",
    "    macd = aba.get_macd(cans)\n",
    "    rsi.plot(ax = sig_ax, alpha = 0.1)\n",
    "    ax4 = sig_ax.twinx()\n",
    "    macd[['macd', 'macd_signal']].plot(ax = ax4)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aba = main.Abathor('LTC-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = []\n",
    "\n",
    "def get_random_candles():\n",
    "    days = np.random.randint(1, 500)\n",
    "    hours = np.random.randint(0, 12)\n",
    "    minutes = np.random.randint(0,60)\n",
    "    start = datetime.today() - timedelta(days = days, hours = hours, minutes = minutes )\n",
    "    end = start + timedelta(seconds = 60 * 200)\n",
    "    cans =  aba.get_candles(start, end)\n",
    "    observations.append(cans)\n",
    "    return cans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o> | 100.00 % \n",
      "Done: 99 Remaining: 1, Remaining Time: 1s\n"
     ]
    }
   ],
   "source": [
    "bar = rt.progress_bar(100)\n",
    "for num in range(0, 100):\n",
    "    get_random_candles()\n",
    "    bar.progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(candle_list, candles_before = 10):\n",
    "    X = []\n",
    "    y = []\n",
    "    ar = np.array\n",
    "    bar = rt.progress_bar(len(candle_list))\n",
    "    for candles in candle_list:\n",
    "        bar.progress()\n",
    "        changes = candles.copy()\n",
    "        changes[['low', 'high', 'open', 'close', 'volume']] = np.log(changes[['low', 'high', 'open', 'close', 'volume']]).diff().bfill()\n",
    "\n",
    "        for index in changes.index:\n",
    "            change_percent = changes.loc[index, 'close']\n",
    "            all_before = changes.loc[:index]\n",
    "            amount = len(all_before)\n",
    "            if amount > candles_before + 2:\n",
    "                Xi = all_before.iloc[amount - (candles_before+ 2):amount-2]\n",
    "                Xi = ar(Xi[['low', 'high', 'open', 'close', 'volume']].values)\n",
    "                X.append(Xi)\n",
    "                y.append(change_percent)\n",
    "    return ar(X), ar(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candles_before = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o0o> | 100.00 % \n",
      "Done: 124 Remaining: 1, Remaining Time: 0s\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_data(observations, candles_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(Y, columns = ['y'])\n",
    "mask = temp['y'] >= 0.005\n",
    "temp.loc[mask, 'new_y'] = 1\n",
    "temp.loc[~mask, 'new_y'] = 0\n",
    "y = temp['new_y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(X, y):\n",
    "    model = kr.models.Sequential()\n",
    "    model.add(kr.layers.LSTM(2**4, input_shape=X.shape[1:],return_sequences=True))\n",
    "    #model.add(kr.layers.Dropout(0.3))\n",
    "    model.add(kr.layers.LSTM(2**4))\n",
    "    model.add(kr.layers.Dense(1))\n",
    "    model.add(kr.layers.Activation('sigmoid'))\n",
    "    optimizer = kr.optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "model = generate_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6511 - val_loss: 0.6501\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5541 - val_loss: 0.6021\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4267 - val_loss: 0.5499\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2837 - val_loss: 0.5270\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1733 - val_loss: 0.5579\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1118 - val_loss: 0.6227\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0825 - val_loss: 0.6963\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0677 - val_loss: 0.7678\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0602 - val_loss: 0.8275\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0561 - val_loss: 0.8796\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0537 - val_loss: 0.9261\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0521 - val_loss: 0.9678\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0512 - val_loss: 1.0064\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0507 - val_loss: 1.0325\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0504 - val_loss: 1.0547\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0501 - val_loss: 1.0614\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0500 - val_loss: 1.0707\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0500 - val_loss: 1.0704\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0499 - val_loss: 1.0680\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0500 - val_loss: 1.0763\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0498 - val_loss: 1.0764\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0497 - val_loss: 1.0822\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0498 - val_loss: 1.0877\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0496 - val_loss: 1.0891\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0496 - val_loss: 1.0881\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0496 - val_loss: 1.0882\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0499 - val_loss: 1.0944\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0498 - val_loss: 1.0971\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0494 - val_loss: 1.1001\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0495 - val_loss: 1.0993\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0496 - val_loss: 1.0976\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0495 - val_loss: 1.0970\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0495 - val_loss: 1.0948\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0494 - val_loss: 1.0947\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0494 - val_loss: 1.0896\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0494 - val_loss: 1.0909\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0494 - val_loss: 1.0879\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0494 - val_loss: 1.0886\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0494 - val_loss: 1.0878\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0494 - val_loss: 1.0873\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0494 - val_loss: 1.0891\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.0495 - val_loss: 1.0917\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.0496 - val_loss: 1.0977\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0493 - val_loss: 1.0929\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0498 - val_loss: 1.1035\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.0492 - val_loss: 1.1047\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0493 - val_loss: 1.1004\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0493 - val_loss: 1.0973\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.0494 - val_loss: 1.0991\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0493 - val_loss: 1.0955\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0493 - val_loss: 1.0986\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0494 - val_loss: 1.1035\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0492 - val_loss: 1.1039\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0491 - val_loss: 1.1023\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0493 - val_loss: 1.1053\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0491 - val_loss: 1.1057\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.0491 - val_loss: 1.1044\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0490 - val_loss: 1.1017\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0491 - val_loss: 1.1053\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.0489 - val_loss: 1.1114\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0487 - val_loss: 1.1074\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0487 - val_loss: 1.1103\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0487 - val_loss: 1.1100\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0481 - val_loss: 1.1068\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.0479 - val_loss: 1.1079\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.0476 - val_loss: 1.1138\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0468 - val_loss: 1.1295\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0467 - val_loss: 1.1395\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0459 - val_loss: 1.1590\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0460 - val_loss: 1.1633\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0457 - val_loss: 1.1679\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0457 - val_loss: 1.1765\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0449 - val_loss: 1.1895\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0450 - val_loss: 1.1881\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.0445 - val_loss: 1.2001\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0445 - val_loss: 1.2241\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0446 - val_loss: 1.2261\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.0444 - val_loss: 1.2288\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0441 - val_loss: 1.2322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0439 - val_loss: 1.2430\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0434 - val_loss: 1.2539\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.0442 - val_loss: 1.2578\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0432 - val_loss: 1.2524\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0440 - val_loss: 1.2617\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0427 - val_loss: 1.2652\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.0433 - val_loss: 1.2784\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.0429 - val_loss: 1.2860\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.0439 - val_loss: 1.2778\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0423 - val_loss: 1.2821\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0426 - val_loss: 1.2798\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0422 - val_loss: 1.2872\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0435 - val_loss: 1.2899\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0429 - val_loss: 1.2966\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.0420 - val_loss: 1.3025\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0433 - val_loss: 1.2995\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.0419 - val_loss: 1.3014\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.0413 - val_loss: 1.3029\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.0416 - val_loss: 1.3085\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.0423 - val_loss: 1.3093\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.0410 - val_loss: 1.3259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xab903dd8>"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[:1000], y[:1000],batch_size=100,  epochs=100, validation_split=0.30, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = aba.get_candles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_cans_to_shape(cans):\n",
    "    changes = candles.copy()\n",
    "    changes[['low', 'high', 'open', 'close', 'volume']] = np.log(changes[['low', 'high', 'open', 'close', 'volume']]).diff().bfill()\n",
    "    changes = changes[['low', 'high', 'open', 'close', 'volume']] \n",
    "    temp = changes.iloc[-8:].values\n",
    "\n",
    "    return np.array([temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "count    1000.000000\n",
      "mean        0.006420\n",
      "std         0.016134\n",
      "min         0.002549\n",
      "25%         0.002598\n",
      "50%         0.002785\n",
      "75%         0.004562\n",
      "max         0.250153\n",
      "dtype: float64\n",
      "y\n",
      "count    1000.000000\n",
      "mean        0.074000\n",
      "std         0.261902\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "dtype: float64\n",
      "Predictions vs y\n",
      "green = y | red = preds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfx41rzblSIT+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb4808be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(X, y):\n",
    "    preds = model.predict(X)\n",
    "    print('Predictions')\n",
    "    print(pd.Series(preds.reshape(len(preds))).describe())\n",
    "    print('y')\n",
    "    print(pd.Series(y).describe())\n",
    "    print('Predictions vs y')\n",
    "    fig, (ax, ax2) = plt.subplots(nrows= 2)\n",
    "    sea.distplot(preds, kde = False, ax = ax, color = 'red')\n",
    "\n",
    "    sea.distplot(y, kde = False, ax = ax2, color = 'green')\n",
    "    print('green = y | red = preds')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "evaluate(X[:1000], y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    100\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['preds'] = preds.reshape(len(preds))\n",
    "data['y'] = y[:100]\n",
    "\n",
    "data[data['preds'] > 0]['y'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
